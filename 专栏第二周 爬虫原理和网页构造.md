# 爬虫原理和页面构造

## 爬虫原理

1. 网络链接

   网络链接就像在火车站买票一样：旅客选择好目的地，投入硬（纸）币或者刷卡，售票机就会给我们一直带有列车信息的车票。

   计算机(乘客)带着**请求头**和**消息体**（目的地，车次等信息）向服务器(售票机)发起一次请求（购买），相应的服务器（售票机）会返回本计算机相应的HTML文件作为Response(相应的车票)。

   > 这里是一个GET请求。我们常见的还有POST请求。

   

![u=2670977504,417194345&fm=15&gp=0 (2)](https://github.com/ai-union/PythonSpyder/blob/master/img/pic2.jpg?raw=true)

2. 爬虫原理

   了解了网络连接的基本原理后，爬虫原理就好理解了。网络连接需要计算机一次Request请求和服务器端的Response回应。爬虫也需要做两件事：

   - 模拟计算机对服务器发起Request请求。
   - 接收服务器的Response内容并分析其内容，提取出来。

   但是我们要获取的信息通常不是直在一个页面上，这时就需要设计一个爬虫的执行流程。我们常用的有两种：

   - 多页面爬虫流程

     通常这样的网站有很多页面，且每个页面的构造都类似。因此，可以使用如下流程：

     - 手动翻页并观察各网页的URL构成特点，构造出所有的页面URL保存到列表中。
     - 根据URL列表一次循环取出URL
     - 循环调用爬虫函数，存储数据。
     - 循环结束，爬虫运行结束。

     ```mermaid
     graph TD
     A(开始) --> B[构建URL列表]
     B --> C{是否循环}
     C -->|是|D[爬取数据]
     D-->E[存储数据]
     C-->|否|F[停止爬取数据]
     F-->G(结束)
     ```

   - 跨页面爬虫流程

     - 定义爬取函数爬取列表（目录）的所有专题的URL。
     - 将专题URL存入列表中(种子URL)。
     - 定义爬取详细页数据函数。
     - 进入专题详细页面爬取详细页数据。
     - 存储数据，循环完毕，爬虫结束

     ```mermaid
     graph TD
     A(开始)-->B[爬取列表页URL]
     B-->C[URL存入列表]
     C-->D{是否循环}
     D-->|是|E[爬取详细页数据]
     E-->F[存储数据]
     D-->|否|G[停止爬取]
     G-->H(结束)
     ```

##  页面构造

1. 推荐使用谷歌浏览器

2. 页面构造

   1. 我们常说的网页大部分都是用HTML语言来写的。HTML是按层级规定所属关系。

      ```html
      <html>
          <head>
              这部分页面都是定义网页样式和js
              
          </head>
          <body>
              <div>
                  <table>
                      <tr>
                      	<td>
                          </td>
                      </tr>
                       <tr>
                      	<td>
                          </td>
                      </tr>
                  </table>
              </div>
          </body>
      </html>
      ```

      > 上面的段代码，就是HTML代码了。
      >
      > 我们通常成<div>这样的代码为**标签**，即这是一个**DIV标签**。
      >
      > - 我们称DIV标签是table标签的**父节点**
      > - 称tr标签是table标签的**子节点**
      > - 称tr标签为div标签的**孙节点**
      > - 称两个tr的关系为**兄弟节点**

      我们这里由于篇幅原因暂不对前端知识做更深入的说明了。我们会在实际项目中和大家慢慢分享相关的知识点。欢迎大家持续关注本专栏。

   2. 查询网信息

      我们在打开要爬取的目标网站，然后通过F12快捷键即可看到如下页面

      ![1565418696252](https://github.com/ai-union/PythonSpyder/blob/master/img/1565418696252.png?raw=true)

      在这里我们可以很方便的查看目标网站的页面构成。

